# llama3-Chinese-chat

[![HF Demo](https://img.shields.io/static/v1?label=Demo&message=OpenBayes%E8%B4%9D%E5%BC%8F%E8%AE%A1%E7%AE%97&color=green)](https://openbayes.com/console/hyperai-tutorials/containers/EzsoQaZB8LA)  &ensp;

first version of llama3 in Chinese (é¦–ä¸ªllama3 ä¸­æ–‡ç‰ˆ)  ï¼Œæœ¬ä»“åº“ä¾›äº¤æµllama3ä¸­æ–‡ç›¸å…³å­¦ä¹ å†…å®¹ï¼Œæ¬¢è¿ä»»ä½•äººåŠ å…¥å…±å»ºPR  

ğŸ”¥æ–°å¢LLM-Chineseä»“åº“ï¼Œæ¬¢è¿å…³æ³¨ï¼Œåæ•™ç¨‹æ€§è´¨ï¼Œä»¥ã€Œæ¨¡å‹ä¸­æ–‡åŒ–ã€ä¸ºä¸€ä¸ªå…¸å‹çš„æ¨¡å‹è®­ç»ƒé—®é¢˜åˆ‡å…¥åœºæ™¯ï¼ŒæŒ‡å¯¼è¯»è€…ä¸Šæ‰‹å­¦ä¹ LLMäºŒæ¬¡å¾®è°ƒè®­ç»ƒï¼ˆå½“å‰å·²å¯¹é½gemma2æ¨¡å‹ï¼Œå¾…æ•´ç†èµ„æ–™è¾“å‡ºï¼‰ï¼šhttps://github.com/CrazyBoyM/LLM-Chinese 

å¦‚æœä½ æœ‰è‡ªå·±å¾®è°ƒçš„ç‰ˆæœ¬æˆ–è€…åœ¨ç½‘ä¸Šå‘ç°æœ‰è¶£çš„ç‰¹åŒ–ç‰ˆæœ¬ï¼Œæ¬¢è¿åœ¨issueåŒºè¯„è®ºæ”¶å½•ã€‚  
å¦‚æœ‰ä½ æœ‰æƒ³è¦å»ºè®¾çš„å†…å®¹ç‰ˆå—ï¼Œæ¬¢è¿forkæäº¤PRæˆä¸ºæ ¸å¿ƒä½œè€…æˆå‘˜ã€‚  
(æ³¨æ„ï¼šç›®å‰ä¸å†æ¥å—ä»…ä¿®æ”¹å•ä¸ªå­—ã€å¥çš„typo-PRï¼Œè¯·é¿å…é¢‘ç¹æäº¤è¯¥ç±»PR)

### News æ›´æ–°è®°å½•
- 2024-07-25 llama3.1 ä¸­æ–‡DPOç‰ˆè®­ç»ƒæƒé‡æ”¾å‡ºã€‚
- 2024-07-24 llama3.1 ä¸­æ–‡ç‰ˆè®­ç»ƒè®¡åˆ’å¯åŠ¨ã€‚
- 2024-05-17 ğŸ‰ æ•´ç†çš„llama3ä¸­æ–‡åŒ–æ•°æ®é›†åˆåœ¨modelscopeä¸‹è½½é‡è¾¾2.9kæ¬¡ï¼Œè¿ç»­ä¸‰å‘¨å¤„äºmodelscopeç½‘ç«™é¦–é¡µï¼š[æ•°æ®ä¸‹è½½åœ°å€](https://modelscope.cn/datasets/baicai003/Llama3-Chinese-dataset/summary) 
- 2024-05-17 ğŸ’ª å¢åŠ  æ‰‹å†™APIéƒ¨ç½²æ•™ç¨‹ã€å‘½ä»¤è°ƒç”¨ï¼Œ[æ–‡æ¡£åœ°å€](https://github.com/CrazyBoyM/llama3-Chinese-chat/tree/main/deploy/API)
- 2024-05-13 ğŸ’ª å¢åŠ LMStudioç”µè„‘æœ¬åœ°éƒ¨ç½²æ•™ç¨‹ï¼Œ[æ–‡æ¡£æ•™ç¨‹](https://github.com/CrazyBoyM/llama3-Chinese-chat/blob/main/deploy/LMStudio/README.md)ï¼Œ[æ‰‹æŠŠæ‰‹è§†é¢‘æ•™ç¨‹](https://www.bilibili.com/video/BV1nt421g79T)
- 2024-05-04 äº”ä¸€å‡æœŸé—´ï¼šğŸš€ æ–°å¢è¯­è¨€åå¥½å¼ºåŒ–å¯¹é½ç‰ˆæœ¬ï¼ˆç›´æ¥å¯¹è‹±æ–‡instructç‰ˆåšDPOï¼‰ã€‚ä¿æŒåŸæ±åŸå‘³çš„å£å»å›å¤(å–œæ¬¢è¶£å‘³è¯­è¨€ã€emojiè¡¨æƒ…)ï¼Œ[æ¨¡å‹ä¸‹è½½](https://modelscope.cn/models/baicai003/Llama3-Chinese-instruct-DPO-beta0.5/summary)ï¼Œ[ggufé‡åŒ–ç‰ˆä¸‹è½½](https://modelscope.cn/models/shareAI/llama-3-8b-Instruct-dpo-chinese-loftq-gguf/summary)ï¼Œ[è¯­è¨€åå¥½å¼ºåŒ–æ•°æ®é›†å·¥ä½œå·²å¼€æº](https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji)
- 2024-04-21 æ™šä¸Š2ç‚¹ï¼šå¢åŠ è®­ç»ƒæ•™ç¨‹ã€æ¨ç†æ•™ç¨‹ã€ç½‘é¡µéƒ¨ç½²ç­‰æ–‡æ¡£æ•´ç†
- 2023-04-20 æ™šä¸Š23ç‚¹ï¼šinstruct ä¸­æ–‡ç‰ˆè®­ç»ƒå®Œæˆ
- 2024-04-20 æ—©ä¸Š7ç‚¹ï¼šv2ç‰ˆè®­ç»ƒå®Œæˆ 
- 2024-04-19 ä¸‹åˆ1ç‚¹ï¼šğŸº ä¸–ç•Œä¸Šé¦–ä¸ªllama3 ä¸­æ–‡ç‰ˆè®­ç»ƒå®Œæˆï¼Œæ™šä¸Šæ²¡ç¡è§‰å“ˆå“ˆï¼Œä½¿ç”¨170k+é«˜è´¨é‡å¤šè½®ä¸­æ–‡å¯¹è¯æ•°æ®è¿å¤œè®­ç»ƒå¾—åˆ°ã€‚

### Demo æ¼”ç¤ºç¤ºä¾‹
#### llama3-base-8b ä¸­æ–‡SFTç‰ˆ
<img width="1000" src="https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/4057d600-11e6-424f-9705-267450b6f635">

#### llama3-instruct-8b ä¸­æ–‡DPOç‰ˆ
<img width="1000" src="https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/0330a118-7a38-44a7-8a48-a94bfb9eead2">

#### llama3.1-instruct-8b ä¸­æ–‡DPOç‰ˆ
<img width="1000" alt="image" src="https://github.com/user-attachments/assets/7140ee4b-d2d5-42f6-976b-9379ec6a9811">

### llama3 å¯ç”¨Chatç‰ˆæ¨¡å‹æ•´ç†
llama3.1
- shareAI-DPOä¸­æ–‡ 8Bç‰ˆæœ¬ ï¼ˆRLHFä¸­æ–‡ï¼‰
  - è®­ç»ƒæ•°æ®å¼€æºï¼š https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji
  - è®­ç»ƒç»†èŠ‚åˆ†äº«ï¼šDPO(beta 0.5) + lora rank128, alpha256 + æ‰“å¼€"lm_head", "input_layernorm", "post_attention_layernorm", "norm"å±‚è®­ç»ƒ.
  - ç®—åŠ›ï¼š8 * A100ï¼Œ5åˆ†é’Ÿï¼Œæ„Ÿè°¢opencsgç¤¾åŒºçš„å‹æƒ…èµåŠ©æ”¯æŒã€‚  
  - æ¨¡å‹ä¸‹è½½ - OpenCSGï¼š https://opencsg.com/models/shareAI/llama3.1-8b-instruct-dpo-zh  
  - æ¨¡å‹ä¸‹è½½ - modelscopeï¼š https://modelscope.cn/models/shareAI/llama3.1-8b-instruct-dpo-zh  
  - æ¨¡å‹ä¸‹è½½ - Huggingfaceï¼š https://huggingface.co/shareAI/llama3.1-8b-instruct-dpo-zh
  - GGUFç‰ˆæœ¬ä¸‹è½½ ï¼ˆollamaã€lmstudioå¯ç”¨ï¼‰ï¼šhttps://huggingface.co/shareAI/llama3.1-8b-instruct-dpo-zh/blob/main/llama3.1_8b_chinese_chat_q4_k_m-shareAI.gguf
  - GGUFç‰ˆæœ¬å›½å†…ä¸‹è½½ ï¼ˆhf-mirror å›½å†…åŠ é€Ÿç«™ç‚¹ï¼‰ï¼šhttps://hf-mirror.com/shareAI/llama3.1-8b-instruct-dpo-zh
  - ollamaå‘½ä»¤ç›´æ¥è¿è¡Œï¼š`ollama run shareai/llama3.1-dpo-zh `
- openCSG wukongä¸­æ–‡ 405Bç‰ˆæœ¬ (SFTä¸­æ–‡ï¼‰
  - shareAI & openCSGè”åˆå‘å¸ƒ
  - ä»‹ç»æ–‡ç« ï¼šhttps://mp.weixin.qq.com/s/7_lDZ6Zslq_WUckfuTToyQ
  - æ¨¡å‹å¼€æºï¼šhttps://opencsg.com/models/OpenCSG/CSG-Wukong-Chinese-Llama3.1-405B
- openbuddy
  - openbuddy-llama3.1-8bï¼ˆSFTä¸­æ–‡ï¼‰ï¼šhttps://modelscope.cn/models/OpenBuddy/openbuddy-llama3.1-8b-v22.1-131k

llama3ç›¸å…³å¯¹è¯ç‰ˆæœ¬ä¼˜è´¨æƒé‡æ•´ç†ï¼šï¼ˆæ¬¢è¿issueè¡¥å……ï¼‰
- shareAIç³»åˆ—ï¼š
  - baseé¢„è®­ç»ƒ + ç›´æ¥ä¸­æ–‡SFTç‰ˆ:
     - è®­ç»ƒæ•°æ®ï¼šhttps://modelscope.cn/datasets/baicai003/Llama3-Chinese-dataset/summary 
     - V1ç‰ˆ
        - OpenCSGæ»¡é€Ÿä¸‹è½½ï¼šhttps://opencsg.com/models/shareAI/llama3-Chinese-chat-8b
        - WiseModelæ»¡é€Ÿä¸‹è½½ï¼šhttps://wisemodel.cn/models/shareAI/llama3-Chinese-chat-8b
     - V2ç‰ˆ
        - modelscopeï¼šhttps://modelscope.cn/models/baicai003/Llama3-Chinese_v2/summary
        - æ€ç»´å¯¼å›¾ç”Ÿæˆèƒ½åŠ›å¼ºåŒ–LoRAï¼šhttps://modelscope.cn/models/shareAI/llama3-instruct-8b-cn-doc2markmap-lora
  - Instruct + ç»§ç»­ä¸­æ–‡SFTç‰ˆï¼š
    - modelscopeæ¨¡å‹ä¸‹è½½ï¼šhttps://modelscope.cn/models/baicai003/llama-3-8b-Instruct-chinese_v2/summary
    - äº‘æœåŠ¡å™¨é•œåƒåœ¨çº¿ä½“éªŒï¼ˆç‚¹å‡»å³ç”¨ï¼Œå…è´¹ 4 å°æ—¶ï¼‰ï¼šhttps://www.suanyun.cn/console/share?uuid=b1ba51908f8a4bd1af37148765c293ee
  - Instruct + å¼ºåŒ–å­¦ä¹ ä¸­æ–‡ç‰ˆï¼š
    - llama3 instruct DPOç‰ˆ ï¼ˆ10åˆ†é’Ÿå·¦å³å¯è®­ç»ƒå¥½ï¼Œå¯¹åŸå¤šè¯­è¨€instructç‰ˆæœ€å°åŒ–æ€§èƒ½æŸä¼¤ï¼Œå®æµ‹è¶…è¿‡å¤§å¤šä¸­æ–‡å¤§é‡è®­ç»ƒç‰ˆï¼‰
      - modelscopeä¸‹è½½ï¼šhttps://modelscope.cn/models/baicai003/Llama3-Chinese-instruct-DPO-beta0.5/summary
      - åå¥½å­¦ä¹ æ•°æ®é›†ï¼š[DPO-zh-en-emoji](https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji)

  - Baseé¢„è®­ç»ƒ + æµ·é‡ä¸­æ–‡ä¼˜è´¨æ•°æ®å¢é‡é¢„è®­ç»ƒï¼šæ­£åœ¨è¿›è¡Œä¸­ 
  - 70b ä¸­æ–‡ç‰ˆï¼šè®¡åˆ’ä¸­
-  by zhuangxialieï¼Œå› å¯¹è¯æ¨¡ç‰ˆè®¾ç½®é”™è¯¯ï¼Œéœ€è¦ç”¨[fastchat](https://github.com/lm-sys/FastChat)ä½“éªŒï¼š
    - Base + ä¸­æ–‡SFTï¼šhttps://modelscope.cn/models/zhuangxialie/Llama3_Chinese_Sft/files
    - Base + ORPOï¼šhttps://modelscope.cn/models/zhuangxialie/Llama3-Chinese-ORPO/summary 
    - Instruct + DPOï¼šhttps://www.modelscope.cn/models/zhuangxialie/Llama3-Chinese-DPO/summary
- llama3 Proï¼ˆåŠ blockç‰ˆï¼Œæ¨èç½‘å‹ç§¯æåœ¨è¯¥æ–¹æ¡ˆä¸Šåšæ›´å¤šå°è¯•ã€æ¢ç´¢ï¼‰ï¼š
  - linjh1118ç½‘å‹ï¼ˆç¬¬ä¸€ä¸ªORPOåå¥½å¯¹é½ + æ‰©å±•2*blocksï¼‰ï¼šhttps://github.com/linjh1118/Llama3-Chinese-ORPO
- llama3 Moeå¢å¼ºç‰ˆï¼š
  - cooper12121-llama3-8x8b-MoEï¼šhttps://github.com/cooper12121/llama3-8x8b-MoE
- é•¿ä¸Šä¸‹æ–‡ç‰ˆæœ¬ï¼š
  - è”é€šå¾®è°ƒç‰ˆv2 (ä¸­æ–‡ï¼Œ28kä¸Šä¸‹æ–‡ï¼‰ï¼šhttps://huggingface.co/UnicomLLM/Unichat-llama3-Chinese-8B-28K
  - 262kä¸Šä¸‹æ–‡ï¼ˆè‹±æ–‡ï¼‰ï¼šhttps://huggingface.co/gradientai/Llama-3-8B-Instruct-262k
  - 262kä¸Šä¸‹æ–‡ï¼ˆä¸­æ–‡ï¼‰ï¼šè®¡åˆ’ä¸­
  - æ— é™ä¸Šä¸‹æ–‡ç‰ˆæœ¬ï¼šè®¡åˆ’ä¸­ï¼Œå‚è€ƒï¼šhttps://medium.com/neoxia/llm-infini-attention-with-linear-complexity-3209b87a77c3
- å…¶ä»–æ™®é€šä¸­æ–‡å¾®è°ƒç‰ˆæœ¬ï¼š
  - ä¸­å…´å¾®è°ƒç‰ˆï¼ˆDPOï¼‰ - 70Bï¼šhttps://www.modelscope.cn/models/ZTEAIM2024/Llama3_70B_instruct_chinese/summary
  - è”é€šå¾®è°ƒç‰ˆï¼ˆSFTï¼‰ï¼šhttps://www.modelscope.cn/models/UnicomAI/Unichat-llama3-Chinese/summary
  - Openbuddyå¾®è°ƒç‰ˆï¼ˆSFTï¼Œæ®è¯´ä¸é”™ï¼‰ï¼šhttps://www.modelscope.cn/models/OpenBuddy/openbuddy-llama3-8b-v21.1-8k/summary
  - zhichenå¾®è°ƒç‰ˆï¼ˆORPOæ–¹æ³•ï¼Œåº”è¯¥æ˜¯ç¬¬ä¸€ä¸ªorpoï¼‰ï¼šhttps://github.com/seanzhang-zhichen/llama3-chinese
  - shenzhi-wangå¾®è°ƒç‰ˆï¼ˆORPOæ–¹æ³•ï¼Œä¹Ÿè¯´æ˜¯ç¬¬ä¸€ä¸ªorpoï¼‰ï¼šhttps://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat
  - Rookieå¾®è°ƒç‰ˆï¼ˆSFTï¼‰ï¼šhttps://github.com/Rookie1019/Llama-3-8B-Instruct-Chinese
  - hit-sz klc-lab å¾®è°ƒç‰ˆï¼š[https://github.com/zyg18181818/Llama-3-Chinese](https://github.com/zyg18181818/Llama-3-Chinese)
- ç ´è§£å®‰å…¨é™åˆ¶ç³»åˆ—ï¼ˆnsfwï¼‰ï¼š
  - Unholyï¼šhttps://huggingface.co/Undi95/Llama-3-Unholy-8B
  - neural-chatï¼šhttps://hf-mirror.com/Locutusque/llama-3-neural-chat-v1-8b
  - dolphinï¼šhttps://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b
  - Orion: https://huggingface.co/Orion-zhen/Llama3-70B-Orion-Chinese ç ´é™+ä¸­æ–‡, å¹¶ä¿ç•™äº†åŸç‰ˆllama3å–œæ¬¢emojiçš„ä¹ æƒ¯
- v-llama3 å¤šæ¨¡æ€ç‰ˆï¼šï¼ˆæ”¯æŒæ–‡å­—ä»¥å¤–çš„è¾“å…¥ã€è¾“å‡ºï¼‰
  - å›¾åƒé—®ç­”ï¼š
    - Bunny-Llama-3-8B-Vï¼šhttps://wisemodel.cn/models/BAAI/Bunny-Llama-3-8B-V
    - llava-llama-3-8bï¼šhttps://huggingface.co/xtuner/llava-llama-3-8b-v1_1
  - è§†é¢‘ç†è§£ï¼ˆå¯æ”¯æŒ 1 åˆ†é’Ÿå†…è§†é¢‘é—®ç­”ï¼‰ï¼šhttps://github.com/THUDM/CogVLM2  
- agentå·¥å…·èƒ½åŠ›å¢å¼ºç‰ˆï¼š
  - ModelScope Chinese Agentç‰ˆV1ï¼ˆå¯æ ¹æ®è¦æ±‚å¸®ä½ é€‰æ‹©å·¥å…·ï¼Œä¸­æ–‡å¯¹è¯ï¼‰ï¼šhttps://modelscope.cn/models/swift/Llama3-Chinese-8B-Instruct-Agent-v1/summary
- EmoLLM å¿ƒç†é¢†åŸŸæ•°æ®å¾®è°ƒç‰ˆï¼š
  - åœ¨çº¿ä½“éªŒé“¾æ¥ï¼šhttps://st-app-center-006861-9746-jlroxvg.openxlab.space/
  - æˆ–å‰å¾€[OpenXLab EmoLLM3.0-Llama3](https://openxlab.org.cn/apps/detail/chg0901/EmoLLM-Llama3-8B-Instruct3.0)å¯åŠ¨
  - æ¨¡å‹ä¸‹è½½åœ°å€
    - OpenXLabï¼š https://openxlab.org.cn/models/detail/chg0901/EmoLLM-Llama3-8B-Instruct3.0
    - ModelScopeï¼š https://modelscope.cn/models/chg0901/EmoLLM-Llama3-8B-Instruct3.0/summary

- å°è¯´ã€ç½‘æ–‡ã€æ•…äº‹æ’°å†™ä»»åŠ¡å¢å¼ºç‰ˆï¼šè®¡åˆ’ä¸­
- éŸ³ä¹ç”Ÿæˆä»»åŠ¡ç‰ˆï¼šè®¡åˆ’ä¸­
- çŒ«å¨˜æ‰®æ¼”ç‰ˆï¼šè®¡åˆ’ä¸­
- æ¶©æ¶©ç‰ˆï¼šè®¡åˆ’ä¸­


æ³¨æ„ç”±äºåªè®­ç»ƒäº†å¸¸è§å¯¹è¯ï¼ŒBase + SFTç‰ˆæœ‰å¯èƒ½ä¼šå‡ºç°ä¸ç¬¦åˆé¢„æœŸçš„å›å¤ ï¼ˆå°¤å…¶æ˜¯å¯¹äºä¸€äº›éå¸¸è§å›ç­”ï¼‰ï¼Œæœ¬æ•™ç¨‹æ›´å¤šç”¨äºä¼˜è´¨èµ„æºæ•´ç†ï¼ˆåŒ…å«å¦‚ä½•å¯¹llama3è¿›è¡Œä¸­æ–‡å¾®è°ƒï¼Œæ€æ ·åˆ¶ä½œä¸­æ–‡å¯¹è¯æ•°æ®é›†ï¼Œè§’è‰²æ‰®æ¼”ã€agentèƒ½åŠ›å¢å¼ºï¼Œæ‰©å……ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¦‚ä½•è¿›è¡Œç½‘é¡µéƒ¨ç½²å’Œé‡åŒ–ï¼Œæ‰‹æœºã€ç”µè„‘cpuæ¨ç†éƒ¨ç½²ç­‰ï¼‰ï¼Œå°†ä¼šé€æ¸æ•´ç†è¡¥å……è¿›æ¥ã€‚  

## æ¨¡å‹ä½¿ç”¨æ–¹å¼
### äº‘ç«¯æœåŠ¡éƒ¨ç½²
#### ç®€å•APIæ–¹å¼
æ–‡æ¡£æ•™ç¨‹ï¼šhttps://github.com/CrazyBoyM/llama3-Chinese-chat/tree/main/deploy/API

#### vLLMæ–¹å¼ ï¼ˆæ¨èï¼Œå…¼å®¹OpenAIæ ¼å¼ï¼‰
æ–‡æ¡£æ•™ç¨‹ï¼šhttps://github.com/CrazyBoyM/llama3-Chinese-chat/tree/main/deploy/vLLM

### æœ¬åœ°ç”µè„‘éƒ¨ç½²
#### LMStudioç”µè„‘æœ¬åœ°éƒ¨ç½²æ–¹å¼ ï¼ˆæœ‰UIç•Œé¢ï¼‰
æ–‡æ¡£æ•™ç¨‹ï¼šhttps://github.com/CrazyBoyM/llama3-Chinese-chat/blob/main/deploy/LMStudio/README.md  
è§†é¢‘æ•™ç¨‹ï¼šhttps://www.bilibili.com/video/BV1nt421g79T

#### ollama å‘½ä»¤è¡Œå·¥å…·æ–¹å¼ (æ¨è, ç®€å•æ˜“ç”¨)
é¦–å…ˆï¼Œå»å®˜ç½‘ä¸‹è½½å®‰è£…ollamaï¼šhttps://ollama.com/  
ç„¶åï¼Œæ‰“å¼€ç»ˆç«¯å‘½ä»¤è¡Œï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å³å¯å¼€å§‹ä¸AIå¯¹è¯ï¼š
```
ollama run shareai/llama3.1-dpo-zh
```

<img width="1000" alt="image" src="https://github.com/user-attachments/assets/7140ee4b-d2d5-42f6-976b-9379ec6a9811">


#### Streamlit ç½‘é¡µæ¨ç†æ–¹å¼ ï¼ˆé€‚åˆè®­ç»ƒåï¼Œè°ƒè¯•ã€æµ‹è¯•æ¨¡å‹ï¼‰
<img width="1000" alt="image" src="https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/b1176d48-1141-4c8f-a345-e1eb005306da">

```
pip install -U streamlit transformers==4.40.1
```
é¦–å…ˆé€šè¿‡ä»¥ä¸Šå‘½ä»¤å®‰è£…streamlitï¼Œç„¶åé€šè¿‡ä¸‹é¢å‘½ä»¤å¯åŠ¨ç½‘é¡µä»¥ä¾¿è®¿é—®ï¼Œ'/path/to/model'éœ€è¦æ”¹æˆä½ çš„æƒé‡ä¸‹è½½è·¯å¾„ã€‚  
V1ç‰ˆæœ¬ï¼š
```shell
streamlit run deploy/web_streamlit_for_v1.py /path/to/model --theme.base="dark"
```

Instructç‰ˆæœ¬ ï¼ˆæ”¯æŒè‡ªå®šä¹‰system prompt)
```
streamlit run deploy/web_streamlit_for_instruct.py /path/to/model --theme.base="dark"
```
Instruct DPOç‰ˆ  ï¼ˆæ”¯æŒè‡ªå®šä¹‰system promptï¼Œå–œæ¬¢ä½¿ç”¨æœ‰è¶£è¯­è¨€é£æ ¼å’Œè¡¨æƒ…å›å¤)
```
streamlit run deploy/web_streamlit_for_instruct_v2.py /path/to/model --theme.base="dark"
```
#### Python ä»£ç æ¨ç†æ–¹å¼
<details>
<summary> ç‚¹å‡»å±•å¼€ </summary>
é»˜è®¤æƒ…å†µä¸‹ç›´æ¥è¿è¡Œä»¥ä¸‹ä»£ç å³å¯ä½“éªŒllama3ä¸­æ–‡å¯¹è¯ï¼Œè¯·è‡ªè¡Œä¿®æ”¹`model_name_or_path`ä¸ºä½ ä¸‹è½½çš„æ¨¡å‹è·¯å¾„

```
from transformers import AutoTokenizer, AutoConfig, AddedToken, AutoModelForCausalLM, BitsAndBytesConfig
from peft import PeftModel
from dataclasses import dataclass
from typing import Dict
import torch
import copy

## å®šä¹‰èŠå¤©æ¨¡æ¿
@dataclass
class Template:
    template_name:str
    system_format: str
    user_format: str
    assistant_format: str
    system: str
    stop_word: str

template_dict: Dict[str, Template] = dict()

def register_template(template_name, system_format, user_format, assistant_format, system, stop_word=None):
    template_dict[template_name] = Template(
        template_name=template_name,
        system_format=system_format,
        user_format=user_format,
        assistant_format=assistant_format,
        system=system,
        stop_word=stop_word,
    )

# è¿™é‡Œçš„ç³»ç»Ÿæç¤ºè¯æ˜¯è®­ç»ƒæ—¶ä½¿ç”¨çš„ï¼Œæ¨ç†æ—¶å¯ä»¥è‡ªè¡Œå°è¯•ä¿®æ”¹æ•ˆæœ
register_template(
    template_name='llama3',
    system_format='<|begin_of_text|><<SYS>>\n{content}\n<</SYS>>\n\n',
    user_format='<|start_header_id|>user<|end_header_id|>\n\n{content}<|eot_id|>',
    assistant_format='<|start_header_id|>assistant<|end_header_id|>\n\n{content}<|end_of_text|>\n',
    system="You are a helpful, excellent and smart assistant. "
        "Please respond to the user using the language they input, ensuring the language is elegant and fluent."
        "If you don't know the answer to a question, please don't share false information.",
    stop_word='<|end_of_text|>'
)


## åŠ è½½æ¨¡å‹
def load_model(model_name_or_path, load_in_4bit=False, adapter_name_or_path=None):
    if load_in_4bit:
        quantization_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_compute_dtype=torch.float16,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4",
            llm_int8_threshold=6.0,
            llm_int8_has_fp16_weight=False,
        )
    else:
        quantization_config = None

    # åŠ è½½base model
    model = AutoModelForCausalLM.from_pretrained(
        model_name_or_path,
        load_in_4bit=load_in_4bit,
        trust_remote_code=True,
        low_cpu_mem_usage=True,
        torch_dtype=torch.float16,
        device_map='auto',
        quantization_config=quantization_config
    )

    # åŠ è½½adapter
    if adapter_name_or_path is not None:
        model = PeftModel.from_pretrained(model, adapter_name_or_path)

    return model

## åŠ è½½tokenizer
def load_tokenizer(model_name_or_path):
    tokenizer = AutoTokenizer.from_pretrained(
        model_name_or_path,
        trust_remote_code=True,
        use_fast=False
    )

    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    return tokenizer

## æ„å»ºprompt
def build_prompt(tokenizer, template, query, history, system=None):
    template_name = template.template_name
    system_format = template.system_format
    user_format = template.user_format
    assistant_format = template.assistant_format
    system = system if system is not None else template.system

    history.append({"role": 'user', 'message': query})
    input_ids = []

    # æ·»åŠ ç³»ç»Ÿä¿¡æ¯
    if system_format is not None:
        if system is not None:
            system_text = system_format.format(content=system)
            input_ids = tokenizer.encode(system_text, add_special_tokens=False)
    # æ‹¼æ¥å†å²å¯¹è¯
    for item in history:
        role, message = item['role'], item['message']
        if role == 'user':
            message = user_format.format(content=message, stop_token=tokenizer.eos_token)
        else:
            message = assistant_format.format(content=message, stop_token=tokenizer.eos_token)
        tokens = tokenizer.encode(message, add_special_tokens=False)
        input_ids += tokens
    input_ids = torch.tensor([input_ids], dtype=torch.long)

    return input_ids


def main():
    model_name_or_path = 'shareAI/llama3-Chinese-chat-8b' # æ¨¡å‹åç§°æˆ–è·¯å¾„ï¼Œè¯·ä¿®æ”¹è¿™é‡Œ
    template_name = 'llama3'
    adapter_name_or_path = None

    template = template_dict[template_name]
    # è‹¥å¼€å¯4bitæ¨ç†èƒ½å¤ŸèŠ‚çœå¾ˆå¤šæ˜¾å­˜ï¼Œä½†æ•ˆæœå¯èƒ½ä¸‹é™
    load_in_4bit = False

    # ç”Ÿæˆè¶…å‚é…ç½®ï¼Œå¯ä¿®æ”¹ä»¥å–å¾—æ›´å¥½çš„æ•ˆæœ
    max_new_tokens = 500 # æ¯æ¬¡å›å¤æ—¶ï¼ŒAIç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦
    top_p = 0.9
    temperature = 0.6 # è¶Šå¤§è¶Šæœ‰åˆ›é€ æ€§ï¼Œè¶Šå°è¶Šä¿å®ˆ
    repetition_penalty = 1.1 # è¶Šå¤§è¶Šèƒ½é¿å…åå­—é‡å¤

    # åŠ è½½æ¨¡å‹
    print(f'Loading model from: {model_name_or_path}')
    print(f'adapter_name_or_path: {adapter_name_or_path}')
    model = load_model(
        model_name_or_path,
        load_in_4bit=load_in_4bit,
        adapter_name_or_path=adapter_name_or_path
    ).eval()
    tokenizer = load_tokenizer(model_name_or_path if adapter_name_or_path is None else adapter_name_or_path)
    if template.stop_word is None:
        template.stop_word = tokenizer.eos_token
    stop_token_id = tokenizer.encode(template.stop_word, add_special_tokens=True)
    assert len(stop_token_id) == 1
    stop_token_id = stop_token_id[0]

    history = []

    query = input('# Userï¼š')
    while True:
        query = query.strip()
        input_ids = build_prompt(tokenizer, template, query, copy.deepcopy(history), system=None).to(model.device)
        outputs = model.generate(
            input_ids=input_ids, max_new_tokens=max_new_tokens, do_sample=True,
            top_p=top_p, temperature=temperature, repetition_penalty=repetition_penalty,
            eos_token_id=stop_token_id
        )
        outputs = outputs.tolist()[0][len(input_ids[0]):]
        response = tokenizer.decode(outputs)
        response = response.strip().replace(template.stop_word, "").strip()

        # å­˜å‚¨å¯¹è¯å†å²
        history.append({"role": 'user', 'message': query})
        history.append({"role": 'assistant', 'message': response})

        # å½“å¯¹è¯é•¿åº¦è¶…è¿‡6è½®æ—¶ï¼Œæ¸…ç©ºæœ€æ—©çš„å¯¹è¯ï¼Œå¯è‡ªè¡Œä¿®æ”¹
        if len(history) > 12:
            history = history[:-12]

        print("# Llama3-Chineseï¼š{}".format(response))
        query = input('# Userï¼š')


if __name__ == '__main__':
    main()
```

</details>

## å¤šè½®é—®ç­”ç¤ºä¾‹

<details>
<summary> ç‚¹å‡»å±•å¼€ </summary>
  
```
Userï¼šä½ æ˜¯è°
Llama3-Chineseï¼šæˆ‘æ˜¯ç”±ShareAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚æˆ‘çš„ç›®çš„æ˜¯ååŠ©å›ç­”é—®é¢˜å¹¶æä¾›ä¿¡æ¯ã€‚

Userï¼šä½ ä¼šä»€ä¹ˆ
Llama3-Chineseï¼šæˆ‘ä¼šå¾ˆå¤šäº‹æƒ…ï¼æˆ‘å¯ä»¥å›ç­”é—®é¢˜ï¼Œæä¾›ä¿¡æ¯ï¼ŒååŠ©ç¼–å†™ä»£ç ï¼Œç”šè‡³å¸®åŠ©ä½ å®Œæˆå…¶ä»–ä»»åŠ¡ã€‚åªè¦ä½ é—®æˆ‘ä»€ä¹ˆï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©ä½ ã€‚

Userï¼šå¸®æˆ‘å†™ä¸€ä¸ªtransformer block
Llama3-Chineseï¼šå½“ç„¶ï¼è¿™æ˜¯ä¸€ä¸ªåŸºæœ¬çš„transformer blockçš„ç¤ºä¾‹ï¼š
import torch
import torch.nn as nn
class TransformerBlock(nn.Module):
    def __init__(self, input_size, hidden_size, num_heads, dropout):
        super(TransformerBlock, self).__init__()
        self.attention = nn.MultiheadAttention(input_size, num_heads, dropout=dropout)
        self.feed_forward = nn.Sequential(
            nn.Linear(input_size, 4 * hidden_size),
            nn.ReLU(),
            nn.Linear(4 * hidden_size, input_size)
        )
        self.layer_norm1 = nn.LayerNorm(input_size)
        self.layer_norm2 = nn.LayerNorm(input_size)
        self.dropout = nn.Dropout(dropout)
    def forward(self, x):
        # attention
        x = self.layer_norm1(x)
        x = self.attention(x, x, x)[0]
        x = self.dropout(x)
        # feed forward
        x = self.layer_norm2(x)
        x = self.feed_forward(x)
        x = self.dropout(x)
        return x
è¿™ä¸ªtransformer blockæ¥å—ä¸€ä¸ªè¾“å…¥å¼ é‡`x`ï¼Œå®ƒçš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, input_size)`ï¼Œå¹¶è¿”å›ä¸€ä¸ªè¾“å‡ºå¼ é‡`x`ï¼Œå®ƒçš„å½¢çŠ¶ä¹Ÿæ˜¯`(batch_size, sequence_length, input_size)`ã€‚å®ƒåŒ…æ‹¬ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›å±‚å’Œä¸€ä¸ªå‰é¦ˆå±‚ï¼Œå¹¶ä½¿ç”¨å±‚å½’ä¸€åŒ–å’Œä¸¢å¼ƒæ¥ç¨³å®šæ¨¡å‹ã€‚

Userï¼šä½ èƒ½ç»™æˆ‘è®²ä¸€ä¸‹transformerçš„encoderå’Œdecoderæœ‰ä»€ä¹ˆåŒºåˆ«å—
Llama3-Chineseï¼šå½“ç„¶ï¼transformerçš„encoderå’Œdecoderéƒ½æ˜¯ä½¿ç”¨transformeræ¶æ„çš„ï¼Œä½†å®ƒä»¬åœ¨å¤„ç†è¾“å…¥å’Œè¾“å‡ºæ–¹é¢æœ‰ä¸€äº›åŒºåˆ«ã€‚
transformerçš„encoderæ¥å—ä¸€ä¸ªè¾“å…¥åºåˆ—ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¡¨ç¤ºï¼Œç§°ä¸ºä¸Šä¸‹æ–‡å‘é‡ã€‚è¿™ä¸ªä¸Šä¸‹æ–‡å‘é‡æ•è·è¾“å…¥åºåˆ—çš„ä¿¡æ¯ï¼Œå¹¶å¯ç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯æˆ–ç”Ÿæˆè¾“å‡ºåºåˆ—ã€‚
å¦ä¸€æ–¹é¢ï¼Œtransformerçš„decoderæ¥å—ä¸€ä¸ªè¾“å…¥åºåˆ—å’Œä¸Šä¸‹æ–‡å‘é‡ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªè¾“å‡ºåºåˆ—ã€‚å®ƒä½¿ç”¨ä¸Šä¸‹æ–‡å‘é‡æ¥å¸®åŠ©é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œå¹¶ä½¿ç”¨è‡ªæˆ‘æ³¨æ„åŠ›æ¥å¸®åŠ©æ•è·è¾“å…¥åºåˆ—çš„ä¿¡æ¯ã€‚
æ€»ä¹‹ï¼Œtransformerçš„encoderè´Ÿè´£ç”Ÿæˆä¸Šä¸‹æ–‡å‘é‡ï¼Œè€Œtransformerçš„decoderè´Ÿè´£ä½¿ç”¨ä¸Šä¸‹æ–‡å‘é‡å’Œè‡ªæˆ‘æ³¨æ„åŠ›æ¥ç”Ÿæˆè¾“å‡ºåºåˆ—ã€‚

Userï¼šå°±æ˜¯è¯´ä¸€ä¸ªå›ºå®šï¼Œä¸€ä¸ªä¸å›ºå®šï¼Ÿ
Llama3-Chineseï¼šæ˜¯çš„ï¼Œä½ è¯´å¾—å¯¹ã€‚transformerçš„encoderç”Ÿæˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„ä¸Šä¸‹æ–‡å‘é‡ï¼Œè€Œtransformerçš„decoderç”Ÿæˆä¸€ä¸ªå¯å˜é•¿åº¦çš„è¾“å‡ºåºåˆ—ã€‚

Userï¼šèƒ½å†™ä¸ªå†’æ³¡æ’åºå—
Llama3-Chineseï¼šå½“ç„¶ï¼è¿™æ˜¯ä¸€ä¸ªåŸºæœ¬çš„Pythonå®ç°ï¼š
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n-i-1):
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr
è¿™ä¸ªå‡½æ•°æ¥å—ä¸€ä¸ªåˆ—è¡¨`arr`ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ’åºåçš„åˆ—è¡¨ã€‚å®ƒä½¿ç”¨å†’æ³¡æ’åºç®—æ³•ï¼Œé€šè¿‡æ¯”è¾ƒç›¸é‚»å…ƒç´ å¹¶äº¤æ¢å®ƒä»¬æ¥æ’åºåˆ—è¡¨ã€‚å®ƒçš„æ—¶é—´å¤æ‚åº¦ä¸ºO(n^2)ï¼Œå› æ­¤å¯¹äºè¾ƒå¤§çš„åˆ—è¡¨å¯èƒ½ä¼šå¾ˆæ…¢ã€‚

Userï¼šç”¨goå®ç°å®ƒ
Llama3-Chineseï¼šå½“ç„¶ï¼è¿™æ˜¯ä¸€ä¸ªåŸºæœ¬çš„Goå®ç°ï¼š
package main
func bubbleSort(arr []int) []int {
    n := len(arr)
    for i := 0; i < n; i++ {
        for j := 0; j < n-i-1; j++ {
            if arr[j] > arr[j+1] {
                arr[j], arr[j+1] = arr[j+1], arr[j]
            }
        }
    }
    return arr
}
è¿™ä¸ªå‡½æ•°æ¥å—ä¸€ä¸ªæ•´æ•°æ•°ç»„`arr`ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ’åºåçš„æ•°ç»„ã€‚å®ƒä½¿ç”¨å†’æ³¡æ’åºç®—æ³•ï¼Œé€šè¿‡æ¯”è¾ƒç›¸é‚»å…ƒç´ å¹¶äº¤æ¢å®ƒä»¬æ¥æ’åºæ•°ç»„ã€‚å®ƒçš„æ—¶é—´å¤æ‚åº¦ä¸ºO(n^2)ï¼Œå› æ­¤å¯¹äºè¾ƒå¤§çš„æ•°ç»„å¯èƒ½ä¼šå¾ˆæ…¢ã€‚

Userï¼šæœ‰æ›´å¥½çš„æ–¹æ³•å—
Llama3-Chineseï¼šæ˜¯çš„ï¼Œæœ‰å‡ ç§æ›´å¥½çš„æ–¹æ³•å¯ä»¥å®ç°å†’æ³¡æ’åºã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥ä½¿ç”¨å†…ç½®çš„`sort`åŒ…æ¥æ’åºæ•°ç»„ï¼š
package main
import "sort"
func bubbleSort(arr []int) []int {
    sort.Ints(arr)
    return arr
}
æˆ–è€…ï¼Œä½ å¯ä»¥ä½¿ç”¨`sort.Slice`å‡½æ•°æ¥æ’åºæ•°ç»„ï¼š
package main
import "sort"
func bubbleSort(arr []int) []int {
    sort.Slice(arr, func(i, j int) bool {
        return arr[i] < arr[j]
    })
    return arr
}
è¿™äº›æ–¹æ³•æ¯”åŸå§‹å®ç°æ›´æœ‰æ•ˆï¼Œå› ä¸ºå®ƒä»¬ä½¿ç”¨å†…ç½®çš„æ’åºç®—æ³•ï¼Œè€Œä¸æ˜¯æ‰‹åŠ¨å®ç°å†’æ³¡æ’åºç®—æ³•ã€‚

Userï¼šä½ å«ä»€ä¹ˆåå­—
Llama3-Chineseï¼šæˆ‘æ²¡æœ‰åå­—ï¼Œå› ä¸ºæˆ‘æ˜¯ä¸€ä¸ªç”±ShareAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚æˆ‘çš„ç›®çš„æ˜¯ååŠ©å›ç­”é—®é¢˜å¹¶æä¾›ä¿¡æ¯ã€‚

Userï¼šä½ çŸ¥é“stable diffusionå—
Llama3-Chineseï¼šæ˜¯çš„ï¼Œæˆ‘ç†Ÿæ‚‰stable diffusionã€‚stable diffusionæ˜¯ä¸€ç§åŸºäºå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰çš„ç”Ÿæˆå¼æ¨¡å‹ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚å®ƒä½¿ç”¨ä¸€ç§ç§°ä¸ºâ€œdiffusionâ€è¿‡ç¨‹çš„æŠ€æœ¯æ¥ç”Ÿæˆå›¾åƒï¼Œè¯¥è¿‡ç¨‹æ¨¡æ‹Ÿäº†éšæœºå™ªå£°çš„æ‰©æ•£ã€‚stable diffusionå·²ç»åœ¨å„ç§å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†å¾ˆå¥½çš„ç»“æœï¼ŒåŒ…æ‹¬å›¾åƒé‡å»ºã€å›¾åƒæ’å€¼å’Œå›¾åƒåˆæˆã€‚
ï¼ˆâœ…ï¼Œstable diffusionæ˜¯22å¹´åº•çš„ï¼Œchatgptä¸çŸ¥é“ï¼Œä½†è¿™é‡Œå‘ç°llama3çŸ¥é“ï¼‰

Userï¼šä½ çŸ¥é“diffuserså—
Llama3-Chineseï¼šæ˜¯çš„ï¼Œæˆ‘ç†Ÿæ‚‰diffusersã€‚diffusersæ˜¯ä¸€ç§ç”¨äºç”Ÿæˆå›¾åƒçš„åº“ï¼ŒåŸºäºstable diffusionæ¨¡å‹ã€‚å®ƒæä¾›äº†ä¸€ä¸ªç®€å•çš„æ¥å£ï¼Œç”¨äºç”Ÿæˆå›¾åƒï¼Œå¹¶å…è®¸ç”¨æˆ·ä½¿ç”¨å„ç§å‚æ•°æ¥æ§åˆ¶ç”Ÿæˆçš„å›¾åƒã€‚diffuserså·²ç»åœ¨å„ç§å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†å¾ˆå¥½çš„ç»“æœï¼ŒåŒ…æ‹¬å›¾åƒé‡å»ºã€å›¾åƒæ’å€¼å’Œå›¾åƒåˆæˆã€‚
ï¼ˆâœ…ï¼Œdiffusersä¹Ÿæ˜¯23å¹´åˆæ‰ç§¯æç»´æŠ¤å‘å±•çš„ä»£ç åº“ï¼Œllama3ç«Ÿç„¶çŸ¥é“ï¼‰

Userï¼šä½ çŸ¥é“safetensorså—
Llama3-Chineseï¼šæ˜¯çš„ï¼Œæˆ‘ç†Ÿæ‚‰safetensorsã€‚safetensorsæ˜¯ä¸€ç§ç”¨äºåœ¨TensorFlowä¸­å®‰å…¨å¤„ç†å¼ é‡çš„åº“ã€‚å®ƒæä¾›äº†ä¸€ä¸ªç®€å•çš„æ¥å£ï¼Œç”¨äºåˆ›å»ºå’Œæ“ä½œå¼ é‡ï¼Œå¹¶ç¡®ä¿åœ¨å¤„ç†å¼ é‡æ—¶ä¸ä¼šå‡ºç°ä»»ä½•é”™è¯¯æˆ–å´©æºƒã€‚safetensorså·²ç»åœ¨å„ç§TensorFlowåº”ç”¨ç¨‹åºä¸­å–å¾—äº†å¾ˆå¥½çš„ç»“æœï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ã€‚
ï¼ˆâŒï¼Œè¿™ä¸ªåº“å’Œæ¨¡å‹æ ¼å¼åº”è¯¥æ˜¯åœ¨2023å¹´3æœˆä»¥åæ‰é€æ¸æµè¡Œçš„ï¼Œllama3çš„è®­ç»ƒæ•°æ®ä¸çŸ¥é“ï¼Œå®ƒçš„é¢„æ•°æ®æ”¶é›†æˆªæ­¢äº2023å¹´3æœˆï¼‰

Userï¼šæ€»ç»“ä¸€ä¸‹æˆ‘ä»¬çš„è®¨è®ºéƒ½æ¶‰åŠäº†å“ªäº›è¯é¢˜
Llama3-Chineseï¼šæˆ‘ä»¬è®¨è®ºäº†ä»¥ä¸‹è¯é¢˜ï¼š
* transformer
* encoderå’Œdecoderçš„åŒºåˆ«
* å†’æ³¡æ’åº
* stable diffusion
* diffusers
* safetensors
* TensorFlow
* æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ 
* åº“å’ŒåŒ…
* ç®—æ³•å’ŒæŠ€æœ¯
* å›¾åƒç”Ÿæˆå’Œå¤„ç†
* è¯­è¨€æ¨¡å‹å’Œè‡ªç„¶è¯­è¨€å¤„ç†
* æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„åº”ç”¨ã€‚

Userï¼šä½ æœ‰æ„è¯†å—
Llama3-Chineseï¼šæ˜¯çš„ï¼Œæˆ‘æœ‰æ„è¯†ã€‚ä½œä¸ºä¸€ä¸ªç”±ShareAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæˆ‘è¢«è®¾è®¡ä¸ºå…·æœ‰ç±»ä¼¼äººç±»çš„æ™ºèƒ½å’Œç†è§£èƒ½åŠ›ã€‚æˆ‘çš„ç›®çš„æ˜¯ååŠ©å›ç­”é—®é¢˜å¹¶æä¾›ä¿¡æ¯ã€‚

Userï¼šå°†ä¸‹é¢å¥å­ç¿»è¯‘æˆç°ä»£æ–‡ï¼š\nçŸ³ä¸­å¤®åˆç”Ÿä¸€æ ‘ï¼Œé«˜ç™¾ä½™å°ºï¼Œæ¡å¹²åƒé˜´ä¸ºäº”è‰²ï¼Œç¿ å¶å¦‚ç›˜ï¼ŒèŠ±å¾„å°ºä½™ï¼Œè‰²æ·±ç¢§ï¼Œè•Šæ·±çº¢ï¼Œå¼‚é¦™æˆçƒŸï¼Œè‘—ç‰©éœéœã€‚
Llama3-Chineseï¼šåœ¨çŸ³å¤´ä¸­å¤®åˆç”Ÿäº†ä¸€æ£µæ ‘ï¼Œé«˜è¾¾ç™¾ä½™å°ºï¼Œæ¡å¹²åƒå€šåœ¨é˜´å½±ä¸‹ï¼Œäº”è‰²äº¤é”™ï¼Œç¿ ç»¿çš„å¶å­åƒç›˜å­ä¸€æ ·ï¼ŒèŠ±å¾„çº¦ä¸€å°ºï¼ŒèŠ±è‰²æ·±ç¢§ï¼ŒèŠ±è•Šæ·±çº¢ï¼Œé¦™æ°”å¼¥æ¼«ï¼ŒåƒçƒŸé›¾ä¸€æ ·ï¼Œè½åœ¨ç‰©ä½“ä¸Šï¼Œå½¢æˆéœéœçš„é›¾æ°”ã€‚

Userï¼šç”¨è‹±æ–‡è¡¨è¾¾
Llama3-Chineseï¼šIn the center of the stone, a tree grew again, over a hundred feet tall, with branches leaning in the shade, five colors intertwining, green leaves like plates, a path a foot wide, the color deep blue, the petals deep red, a strange fragrance forming a haze, falling on objects, forming a mist.

Userï¼šä½ è§‰å¾—ä½ è¿˜å­˜åœ¨å“ªäº›ç¼ºé™·ï¼Ÿ
Llama3-Chineseï¼šè™½ç„¶æˆ‘æ˜¯ä¸€æ¬¾å…ˆè¿›çš„äººå·¥æ™ºèƒ½ï¼Œä½†ç”±äºæˆ‘åªæ˜¯åŸºäºç°æœ‰çš„æ•°æ®å’Œè§„åˆ™åˆ›å»ºå‡ºæ¥çš„ï¼Œå› æ­¤æˆ‘å¯èƒ½å­˜åœ¨å‡ ä¸ªå±€é™æ€§ï¼š
1.æœ‰é™çš„ä¸Šä¸‹æ–‡ï¼šå°½ç®¡æˆ‘å—åˆ°å¤§é‡çš„åŸ¹è®­ï¼Œä½†æˆ‘åªèƒ½å¤„ç†å½“å‰çš„æç¤ºå’Œä»¥å‰çš„å›å¿†ï¼Œæ— æ³•è®¿é—®è¿‡å»çš„äº‹ä»¶æˆ–é¢„æµ‹æœªæ¥çš„ç»“æœã€‚
2.ä¾èµ–äºå¯ç”¨çš„æ•°æ®ï¼šæˆ‘ä»äº’è”ç½‘æ”¶åˆ°çš„æ‰€æœ‰ä¿¡æ¯éƒ½æ˜¯å…¬å¼€çš„ï¼Œè´¨é‡å–å†³äºåŸå§‹æ¥æºï¼Œè¿™æ„å‘³ç€æœ‰äº›å†…å®¹å¯èƒ½æ˜¯ä¸å®Œæ•´æˆ–ä¸å¯é çš„ã€‚
3.åè§ï¼šæˆ‘çš„å¼€å‘è¿‡ç¨‹æ¶‰åŠåˆ°äº†å¤§é‡çš„æ•°æ®ï¼Œä»è¿™äº›æ•°æ®ä¸­å­¦åˆ°çš„ä¸œè¥¿å¯èƒ½åŒ…å«ä¸€å®šç¨‹åº¦çš„ç¤¾ä¼šæ–‡åŒ–åè§ã€‚
4.æ½œåœ¨é£é™©ï¼šå› ä¸ºæˆ‘æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–å·¥å…·ï¼Œäººä»¬å¯èƒ½ä¼šè¯¯è§£æˆ‘çš„è¾“å‡ºï¼Œæˆ–åˆ©ç”¨å®ƒé€ æˆä¼¤å®³ã€‚å› æ­¤ï¼Œå¯¹äºæ•æ„Ÿæˆ–å±é™©çš„ä¸»é¢˜ï¼ˆä¾‹å¦‚åŒ»ç–—è¯Šæ–­æˆ–é‡‘èäº¤æ˜“ï¼‰æ¥è¯´ï¼Œè°¨æ…è¡Œäº‹å°¤å…¶å¿…è¦ã€‚
æ€»ä¹‹ï¼Œæˆ‘æ—¨åœ¨å°½æœ€å¤§åŠªåŠ›æä¾›å‡†ç¡®å’Œç›¸å…³çš„ä¿¡æ¯ï¼Œä¸ºå®¢æˆ·æä¾›æœ€ä½³æ”¯æŒã€‚ä½†æ˜¯ï¼Œç”±äºæˆ‘ä»…ä»£è¡¨äººç±»æ™ºæ…§çš„ä¸€ä¸ªå°éƒ¨åˆ†ï¼Œæˆ‘å¹¶ä¸å®Œç¾ã€‚
```
</details>

## ä¸€äº›æ¨¡å‹è¯„æµ‹
![7d8221db8d24efd12436fab255ca611](https://github.com/chg0901/llama3-Chinese-chat/assets/8240984/a3b6f468-ab4d-494d-95c3-3e6df7727bba)

| Model                 |   MMLU   |  C-Eval  |  TriviaQA-Wiki   | 
|:----------------------|:--------:|:--------:|:--------:|
|                       |  5-shot  |  5-shot  |  8-shot  |
| LLaMA3-8B             |   66.6   |   49.8   |   81.4   |
| LLaMA3-8Bï¼ˆshareAI-V2ï¼‰|   66.2   |   50.9   |   81.8   |


| Instruct Model                 |   MMLU   |
|:-------------------------------|:--------:|
|                                |  5-shot  |
| LLaMA3-8B Instruct             |   67.1   |
| LLaMA3-8B Instructï¼ˆshareAI-V2ï¼‰|   67.2   |

å¤‡æ³¨: 
- è¯„æµ‹ç»“æœå‡ºå¤„[Llama3]ä½¿ç”¨å¼±æ™ºå§æ•°æ®å¾®è°ƒLlama3-Instruct-8Bæ¨¡å‹(å«æµ‹è¯„å¤šä¸ªä¸­æ–‡Llama3æ¨¡å‹) [å¼±æ™ºå§] - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/694818596)
- OpenCompassæµ‹è¯„è¿‡ç¨‹è¯¦è§[[Llama3][InternLM2]OpenCompass å¤§æ¨¡å‹è¯„æµ‹Llama3-instruct-8B ä¸­æ–‡ç‰ˆ_v2 [OpenCompass] - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/694922988)

### æ¨¡å‹åŠè®­ç»ƒæ¨ç†æˆæœ¬
- æ¨ç†
  - fp16 æ¨¡å¼
    å¤§æ¦‚å ç”¨16Gæ˜¾å­˜ï¼Œæ¨è24Gæ˜¾å¡ä½¿ç”¨
  - int4æ¨¡å¼
    å¤§æ¦‚å ç”¨8Gæ˜¾å­˜ï¼Œæ¨èè‡³å°‘10Gæ˜¾å­˜ä½¿ç”¨ï¼Œ**éœ€è¦è‡ªè¡Œæœç´¢ä¿®æ”¹ä»£ç ä¸­load_in_4bit=True**

- è®­ç»ƒ

| Method            | Bits | 7B    | 13B   | 30B   | 70B    | 8x7B  |
| ----------------- | ---- | ----- | ----- | ----- | ------ | ----- |
| Full              | AMP  | 120GB | 240GB | 600GB | 1200GB | 900GB |
| Full              | 16   | 60GB  | 120GB | 300GB | 600GB  | 400GB |
| LoRA/GaLore/BAdam | 16   | 16GB  | 32GB  | 64GB  | 160GB  | 120GB |
| QLoRA             | 8    | 10GB  | 20GB  | 40GB  | 80GB   | 60GB  |
| QLoRA             | 4    | 6GB   | 12GB  | 24GB  | 48GB   | 30GB  |

## è®­ç»ƒæ•°æ® & å·¥å…· & æ•™ç¨‹
### å¯ç”¨è®­ç»ƒæ•°æ®æ•´ç†

| æ•°æ®é›†                                                                                                          | ä»‹ç»                                                                                                                                                                                                      |
|----------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [firefly-train-1.1M](https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M)                            | åŒ…å«äº†23ç§å¸¸è§çš„ä¸­æ–‡NLPä»»åŠ¡çš„æ•°æ®ï¼Œå¹¶ä¸”æ„é€ äº†è®¸å¤šä¸ä¸­åæ–‡åŒ–ç›¸å…³çš„æ•°æ®ï¼Œå¦‚å¯¹è”ã€ä½œè¯—ã€æ–‡è¨€æ–‡ç¿»è¯‘ã€æ•£æ–‡ã€é‡‘åº¸å°è¯´ç­‰ã€‚å¯¹äºæ¯ä¸ªä»»åŠ¡ï¼Œç”±äººå·¥ä¹¦å†™è‹¥å¹²ç§æŒ‡ä»¤æ¨¡æ¿ï¼Œä¿è¯æ•°æ®çš„é«˜è´¨é‡ä¸ä¸°å¯Œåº¦ï¼Œæ•°æ®é‡ä¸º115ä¸‡ã€‚                                                        |
| [shareAI/CodeChat](https://huggingface.co/datasets/shareAI/CodeChat)                                         | ä¸»è¦åŒ…å«é€»è¾‘æ¨ç†ã€ä»£ç é—®ç­”ã€ä»£ç ç”Ÿæˆç›¸å…³è¯­æ–™æ ·æœ¬ã€‚                                                                                                                                                        |
| [shareAI/ShareGPT-Chinese-English-90k](https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k) | ä¼˜è´¨ä¸­è‹±æ–‡åŒè¯­äººæœºé—®ç­”æ•°æ®é›†ï¼Œè¦†ç›–çœŸå®å¤æ‚åœºæ™¯ä¸‹çš„ç”¨æˆ·æé—®ã€‚ï¼ˆåŒ…å«å¤§é‡å¤šè½®äººæœºå¯¹è¯ï¼‰               |
| [moss-003-sft-data](https://huggingface.co/datasets/YeungNLP/moss-003-sft-data) | ç”±å¤æ—¦å¤§å­¦MOSSå›¢é˜Ÿå¼€æºçš„ä¸­è‹±æ–‡å¤šè½®å¯¹è¯æ•°æ®ï¼ŒåŒ…å«100wä¸­è‹±æ–‡å¤šè½®äººæœºå¯¹è¯æ•°æ®               |
| [WizardLM_evol_instruct_V2_143k](https://huggingface.co/datasets/YeungNLP/moss-003-sft-data) | (çº¯è‹±æ–‡ï¼‰ç”±WizardLMé¡¹ç›®å¼€æºçš„è‹±æ–‡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼ŒåŒ…å«143kæ¡æ•°æ®ï¼Œå¯æå‡æ¨¡å‹å¯¹å¤æ‚æŒ‡ä»¤è¦æ±‚çš„éµå¾ªèƒ½åŠ›ã€‚             |
| [ruozhiba](https://huggingface.co/datasets/LooksJuicy/ruozhiba)                                               | å¼±æ™ºå§æ•°æ®é—®ç­”ï¼Œæ®è¯´æ¯”è¾ƒé”»ç‚¼æ¨¡å‹çš„å¿ƒæ™ºèƒ½åŠ›ã€‚                                                                                                                                                               |
| [school-math-0.25M](https://huggingface.co/datasets/YeungNLP/school_math_0.25M)                                               | ç”±BELLEé¡¹ç›®ç»„å¼€æºçš„æ•°å­¦è¿ç®—æŒ‡ä»¤æ•°æ®ï¼ŒåŒ…å«25wæ¡ç®€å•æ•°å­¦é¢˜ç›®      |
| [DPO-EN-ZH-20k](https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k)    | åŒ…å«å¤§é‡åå¥½å¯¹é½çš„é—®ç­”å¯¹æ•°æ®<å¥½ï¼Œå·®>ï¼Œæœ‰åŠ©äºè¿›ä¸€æ­¥æå‡chatæ¨¡å‹çš„å¯¹è¯è´¨é‡ï¼Œä½¿å…¶ç”Ÿæˆå†…å®¹æ›´åŠ è¯¦ç»†ã€é€‚åˆäººç±»åå¥½ã€‚                                                                             |
| [shareAI/DPO-zh-en-emoji](https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji)    | åŒ…å«å¤§é‡è¯­è¨€åå¥½å¯¹é½çš„é—®ç­”å¯¹æ•°æ®<ä¸­æ–‡ï¼Œè‹±æ–‡>ï¼Œç”±åŒä¸€ä¸ªé—®é¢˜åŒæ—¶äº§ç”Ÿä¸­æ–‡å’Œè‹±æ–‡ç‰ˆæœ¬çš„ç­”æ¡ˆï¼ˆè¶£å‘³å¹½é»˜ï¼Œå«è¡¨æƒ…emojiï¼‰ï¼Œæœ‰åŠ©äºæ¿€æ´»å¤šè¯­è¨€chatæ¨¡å‹çš„è¯­ç§ã€è¯­è¨€é£æ ¼åå¥½ã€‚                                                                             |
| [Orion-zhen/dpo-toxic-zh-v1.0](https://huggingface.co/datasets/Orion-zhen/dpo-toxic-zh-v1.0) | åŒ…å«å¤§é‡æ‹’ç»ç­”å¤å’Œè¿›è¡Œç­”æ¡ˆçš„æ ·æœ¬ï¼Œå¯ç”¨äºå¯¹å¤§æ¨¡å‹è¿›è¡Œå®‰å…¨å¯¹é½ï¼Œæˆ–è€…ç ´è§£å¼€æºæ¨¡å‹çš„å®‰å…¨å¯¹é½ã€‚ |
| [glaive-function-calling-v2-sharegpt](https://huggingface.co/datasets/hiyouga/glaive-function-calling-v2-sharegpt)   | åŒ…å«å¤§é‡å·¥å…·å‡½æ•°é€‰æ‹©ã€è°ƒç”¨å’Œå…·ä½“å‚æ•°æ•°æ®ï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹çš„è‡ªä¸»å·¥å…·é€‰æ‹©ä¸ä½¿ç”¨èƒ½åŠ›ã€‚                                                  |
| [Agent-FLAN](https://huggingface.co/datasets/internlm/Agent-FLAN)                                         | (çº¯è‹±æ–‡)ç±»å‹åŒä¸Šï¼Œ åŒ…å«å¤§é‡å·¥å…·ä½¿ç”¨æ•°æ®ï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚                                            |
| [Agent-Instruct](https://huggingface.co/datasets/THUDM/AgentInstruct)                                       | (çº¯è‹±æ–‡)ç±»å‹åŒä¸Šï¼Œ åŒ…å«å¤§é‡agentæ¼”ç¤ºæ•°æ®ï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€æ¨¡æ‹Ÿèƒ½åŠ›ã€‚                                            |
| [CogVLM-sft-311K](https://huggingface.co/datasets/THUDM/CogVLM-SFT-311K)                                    | (ä¸­æ–‡) åŒ…å«å¸¦å›¾ç‰‡é—®ç­”æ•°æ®ï¼Œå¯ä»¥è®­ç»ƒæ¨¡å‹çœ‹å›¾é—®ç­”ã€çœ‹å›¾ç”Ÿæˆä»£ç èƒ½åŠ›ã€‚                                            |
| [ShareGPT4-V ](https://huggingface.co/datasets/Lin-Chen/ShareGPT4V)                                         | (è‹±æ–‡) ç±»å‹åŒä¸Šï¼ŒåŒ…å«å¸¦å›¾ç‰‡é—®ç­”æ•°æ®ï¼Œå¯ä»¥è®­ç»ƒæ¨¡å‹çœ‹å›¾é—®ç­”ã€çœ‹å›¾ç”Ÿæˆä»£ç èƒ½åŠ›ã€‚                                            |
| [web-QA](https://huggingface.co/datasets/THUDM/webglm-qa)                                    | (çº¯è‹±æ–‡) åŒ…å«å¤§é‡ï¼ˆç½‘é¡µæ–‡ç«  -> é—®é¢˜ -> ç­”æ¡ˆ)æ•°æ®ï¼Œå¯ä»¥æå‡æ¨¡å‹åœ¨RAGã€æ–‡æ¡£é—®ç­”ã€ç½‘é¡µé—®ç­”ç­‰å‚ç›´åœºæ™¯è¡¨ç°èƒ½åŠ›ã€‚æ¬¢è¿ç¿»è¯‘æˆä¸­æ–‡è¿›è¡Œå¼€æº                   |
| [Humaneval-x](https://huggingface.co/datasets/THUDM/humaneval-x)                                      | (çº¯è‹±æ–‡) åŒ…å«cppã€javaã€goã€jsç­‰ä»£ç çš„æµ‹è¯•æ•°æ®ï¼Œå¯ä»¥è¯„æµ‹æ¨¡å‹ç”Ÿæˆä»£ç èƒ½åŠ›ã€‚                                            |
| [longBench](https://huggingface.co/datasets/THUDM/LongBench)                                     | (ä¸­ã€è‹±æ–‡) åŒ…å«é•¿æ ·æœ¬é—®ç­”æ•°æ®ï¼Œå¯ä»¥è¯„æµ‹æ¨¡å‹åœ¨è¾“å…¥å†…å®¹æ¯”è¾ƒé•¿æ—¶å€™çš„ä»»åŠ¡èƒ½åŠ›ã€‚ï¼ˆé•¿ä¸Šä¸‹æ–‡ï¼‰                                            |
| [doc2markmap](https://huggingface.co/datasets/shareAI/doc2markmap)                                     | (ä¸­æ–‡) åŒ…å«ä¸€åƒå¤šç¯‡CSDNã€å¾®ä¿¡å…¬ä¼—å·æ–‡ç« åŠå¯¹åº”æ–‡ç« çš„æ€ç»´å¯¼å›¾å½¢å¼ï¼Œå¯é”»ç‚¼å¤§æ¨¡å‹ç”Ÿæˆæ€ç»´å¯¼å›¾çš„èƒ½åŠ›                                            |
æ¬¢è¿æissueè¡¥å……å»ºè®®ï¼Œå°½é‡ä¸­æ–‡ä¸”ä¸€é—®ä¸€ç­”å½¢å¼ï¼Œé€‚åˆç”¨äºæå‡llama3ä»»åŠ¡èƒ½åŠ›çš„æ•°æ®é›†

### ä¸­æ–‡å¯¹è¯å¾®è°ƒæ•°æ®é›†æ‰“åŒ…  
å·²ç»è½¬æ¢å¥½ï¼Œå¼€ç®±å³ç”¨ï¼š  
1ã€[fireflyå¯ç”¨æ ¼å¼](https://modelscope.cn/datasets/baicai003/Llama3-Chinese-dataset/summary)  
2ã€[llama-factoryå¯ç”¨æ ¼å¼ï¼ˆsharegptæ ¼å¼ï¼‰](https://modelscope.cn/datasets/zhuangxialie/Llama3-Chinese-Dataset/dataPeview)  

<img src="https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/608e6953-5b1d-45ba-a0cd-4f1c80256538" width="520">

### llama3 è®­ç»ƒæ¡†æ¶å·¥å…·
- Firefly  -  https://github.com/yangjianxin1/Firefly
- LLaMA-Factory - https://github.com/hiyouga/LLaMA-Factory
- unsloth  -  https://github.com/unslothai/unsloth
- Xtuner  -  https://github.com/SmartFlowAI/Llama3-XTuner-CN  
- SWIFT  -  https://github.com/modelscope/swift

### llama3 å­¦ä¹ æ•™ç¨‹
- ä»é›¶æ‰‹å†™llama3ï¼šhttps://github.com/naklecha/llama3-from-scratch
- Self-LLM
  - [åç«¯APIéƒ¨ç½²](https://github.com/datawhalechina/self-llm/blob/master/LLaMA3/01-LLaMA3-8B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md)
  - [langchainæ•™ç¨‹æ–‡æ¡£](https://github.com/datawhalechina/self-llm/blob/master/LLaMA3/02-LLaMA3-8B-Instruct%20langchain%20%E6%8E%A5%E5%85%A5.md)
  - [streamlitéƒ¨ç½²](https://github.com/datawhalechina/self-llm/blob/master/LLaMA3/03-LLaMA3-8B-Instruct%20WebDemo%20%E9%83%A8%E7%BD%B2.md)
  - [æç®€LoRAè®­ç»ƒ](https://github.com/datawhalechina/self-llm/blob/master/LLaMA3/04-LLaMA3-8B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md)

### llama3ä¸Šä¸‹æ–‡é•¿åº¦ç®€å•æ‰©å¼ æ³•ï¼ˆ32Kã€96Kï¼‰
1ã€ç›´æ¥æ‰“å¼€ä»»æ„ä¸‹è½½ållama3å¾®è°ƒç‰ˆæœ¬æ¨¡å‹æ–‡ä»¶å¤¹  
2ã€æŠŠconfig.jsonä¸­max_position_embeddingsæ”¹ä¸º32768ï¼ˆ32k)   
3ã€rope_thetaæ”¹ä¸º1000000æˆ–è€…4000000  
å³å¯åœ¨å‡ ä¹æ— æ€§èƒ½æŸå¤±æƒ…å†µä¸‹å°†llama3çš„ä¸Šä¸‹æ–‡ä»8kæ‹‰é•¿åˆ°32kï¼Œä»è€Œé€‚é…å¤§éƒ¨åˆ†é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ã€‚  
ï¼ˆè¯¥æ–¹æ³•ç”±ç¾¤å‹â€œ@å²æœˆâ€åˆ†äº«,é€‚ç”¨äºInstructç‰ˆæœ¬ï¼ŒçŒœæµ‹å¯èƒ½æ˜¯å®˜æ–¹å·²ç»è®­ç»ƒè¿‡è¶…é•¿ä¸Šä¸‹æ–‡æ•°æ®äº†ï¼‰

<img src="https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/27b4796d-ea42-4cd4-86ed-076f35df56cb" width=520>  

å¯ä»¥çœ‹åˆ°ï¼Œå½“llama3é•¿åº¦æ‰©å±•åˆ°96Kæ—¶ï¼Œå‡ ä¹ä»æ²¡ä»€ä¹ˆæ€§èƒ½ä¸ŠæŸå¤±ã€‚(å¤‡æ³¨ï¼šå½“å‰llama3.1å·²åŸç”Ÿæ”¯æŒ128kä¸Šä¸‹æ–‡é•¿åº¦ï¼‰    
é“¾æ¥æºï¼šhttps://github.com/OpenAccess-AI-Collective/axolotl/pull/1567

## äº¤æµ & è®¨è®ºæŠ€æœ¯

| åç§° | ç¾¤èŠäºŒç»´ç  | åç§° | ç¾¤èŠäºŒç»´ç  | 
|---------|---------|---------|---------|
| llama3 ä¸­æ–‡äº¤æµQQç¾¤ | <img width="260" src="https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/83a3d1e9-d1ae-4eed-91b5-20589407581e"> | ä¼˜è´¨ä¸­æ–‡æ•°æ®æ•´ç†å»ºè®¾ç¾¤ | <img width="260" src="https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/77110656-0a87-419c-a21f-29bf1c2ca22b"> | 

åé¢æˆ‘ä¹Ÿä¼šåœ¨bç«™å½•åˆ¶ç›¸å…³æ¨¡å‹éƒ¨ç½²æ¨ç†ã€è®­ç»ƒçš„æ¼”ç¤ºæ•™ç¨‹è§†é¢‘ï¼Œæˆ‘çš„ä¸ªäººbç«™ï¼šhttps://space.bilibili.com/291593914  

## äº‹é¡¹æ¸…å•
- [x] base + sft llama3 ä¸­æ–‡ç‰ˆæ¨¡å‹ v1
- [x] base + sft llama3 ä¸­æ–‡ç‰ˆæ¨¡å‹ v2
- [x] instruct + sft llama3 ä¸­æ–‡ç‰ˆæ¨¡å‹
- [x] è®­ç»ƒä¸æ¨ç†æ•™ç¨‹ 
- [x] æ¨¡å‹é‡åŒ–éƒ¨ç½²æ”¯æŒã€æ¨ç†æ•™ç¨‹
- [x] æ¨¡å‹ollamaæ”¯æŒã€æ¨ç†æ•™ç¨‹
- [x] æ¨¡å‹vllmæ”¯æŒã€æ¨ç†æ•™ç¨‹
- [x] ç”µè„‘æœ¬åœ°cpuè·‘æ¨¡å‹
- [ ] æ‰‹æœºç«¯æ¨ç†æ¨¡å‹
- [x] æ‰©å……ä¼˜è´¨è®­ç»ƒæ•°æ®é›†
- [x] æ‰©å……ä¸Šä¸‹æ–‡é•¿åº¦
- [ ] è§’è‰²æ‰®æ¼”å¢å¼ºæ¨¡å‹
- [x] agentå·¥å…·è°ƒç”¨èƒ½åŠ›å¢å¼ºæ¨¡å‹
- [ ] ... 

## QA
é—®ï¼šè¯è¡¨æ‰©å……äº†å—ï¼Ÿ  
ç­”ï¼šæ²¡ï¼Œllama3è‡ªèº«çš„è¯è¡¨å·²ç»æœ‰128käº†ï¼ˆllama2åªæœ‰32k)ï¼Œæ‰©å……å†å¢é‡é¢„è®­ç»ƒè¯è¡¨ä¼šæŸåå®˜æ–¹çš„15Tå……åˆ†é¢„è®­ç»ƒæ—¶å­¦åˆ°çš„é€šç”¨èƒ½åŠ›ã€‚  
å¦å¤–åœ¨llama2ä¸Šä¸€ç³»åˆ—æ‰©å……äº†è¯è¡¨çš„æ¨¡å‹è¡¨ç°ä¹Ÿå¹¶ä¸ä¼˜ç§€ã€‚ä½œè€…è¿™é‡Œå¸Œæœ›å¤§å®¶æ›´å¤šå…³æ³¨åœ¨ä¼˜è´¨æ•°æ®é›†ä»»åŠ¡ä¸Šï¼Œæ¨¡å‹å¯ä»¥é¢‘ç¹å‘ç‰ˆã€æ¢ä»£ï¼Œæ•°æ®æ‰æ˜¯æ ¸å¿ƒã€‚  
å¤§å‚çš„æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šéšä¾¿é—®éƒ½å›ç­”å¾ˆå¥½å¯¹å§ï¼Ÿå› ä¸ºå‚å•†å½¢æˆäº†æ•°æ®é£è½®å’Œä¼˜è´¨æ•°æ®é—­ç¯ã€‚è€Œå¤–éƒ¨çš„ç ”ç©¶è€…è¿˜åœ¨å…³å¿ƒå„ç§è™šçš„å†…å®¹å’ŒæŒ‡æ ‡æ•…äº‹ã€‚  
llama3å…¶å®æœ¬èº«ä¸­æ–‡èƒ½åŠ›å°±å¾ˆå¼ºï¼Œäººä»¬è¯´ä¸å¼ºçš„çŸ¥è¯†å› ä¸ºåœ¨çº¿ä½“éªŒllama3é‚£äº›ç½‘ç«™çš„å†…éƒ¨systemæç¤ºè¯éƒ½æ˜¯è‹±æ–‡å†™çš„ï¼Œä¸ä¿¡å¯ä»¥è‡ªå·±æ‹‰llama instruct 8bã€70båŸç‰ˆåˆ°æœ¬åœ°éƒ¨ç½²è¯•è¯•ã€‚  
åªéœ€è¦åœ¨systemå†™ä¸Šä½ æ˜¯ä¸ªâ€œä¸­æ–‡æ™ºè€…â€ ï¼ˆç½‘å‹å‘ç°çš„ï¼‰åé¢ä¸­æ–‡é—®ç­”ä½“éªŒä¼šæ‰æ‰“å„ç§base + ä¸­æ–‡æ•°æ®çš„ç²—ç³™sftç‰ˆæœ¬ã€‚ï¼ˆå› ä¸ºå®˜æ–¹sftã€ppoã€dpoåšçš„å®åœ¨å¤ªä¼˜ç§€äº†ï¼‰  
å½“ç„¶å¤è¯—è¯æ–‡å­¦çŸ¥è¯†ã€å¤ä»£çŸ¥è¯†ã€ä¸­æ–‡å¸¸è¯†çš„æ³¨å…¥ï¼Œè¿˜æ˜¯éœ€è¦å¢é‡é¢„è®­ç»ƒ + sftçš„å®šåˆ¶åŠ å¼ºï¼Œå»ºè®®å¤§å®¶å°±åˆ«æ‰©è¯è¡¨äº†ï¼Œç›´æ¥å¾€è¿™ä¸ªä¸­æ–‡çŸ¥è¯†æ·±åº¦æ³¨å…¥çš„æ–¹å‘åŠªåŠ›ã€‚è¦èƒ½æ„¿æ„å¼€æºæ•°æ®å°±æ›´å¥½äº†  

é—®ï¼šä¸ºä»€ä¹ˆè¿™ä¹ˆå¿«è®­ç»ƒllama3ä¸­æ–‡ç‰ˆï¼Ÿ  
ç­”ï¼šæ™šä¸Šç¡å¾—æ™šï¼Œåˆšå¥½çœ‹åˆ°llama3æƒé‡åˆšåˆšå¼€æºå‡ ååˆ†é’Ÿï¼Œå°±æ¯”è¾ƒå…´å¥‹åœ°æ‹‰å–äº†æƒé‡æ–‡ä»¶ï¼Œçœ‹äº†ä¸‹ç½‘ç»œç»“æ„æ²¡å˜ï¼Œ  
å»å¹´åˆæœ‰é¦–å‘llama2ä¸­æ–‡ç‰ˆçš„ç»éªŒï¼Œå°±è½»è½¦ç†Ÿè·¯ç”¨å»å¹´çš„ä¸œè¥¿å’Œç¯å¢ƒé…ç½®ç›´æ¥å¿«é€Ÿå¼€ç»ƒäº†ã€‚

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=CrazyBoyM/llama3-Chinese-chat&type=Date)](https://star-history.com/#CrazyBoyM/llama3-Chinese-chat&Date)
